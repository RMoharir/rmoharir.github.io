<!DOCTYPE HTML>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rutika Moharir</title>
  
  <meta name="author" content="Rutika Moharir">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <script src='https://kit.fontawesome.com/a076d05399.js'></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cmu-logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Rutika Moharir</name>
                </p>
                <p>I am a Masters in Computer Vision student at the <a href="https://www.ri.cmu.edu/" >Robotics Institute</a>, part of the <a href="https://www.scs.cmu.edu/" >School of Computer Science</a> at <a href="https://www.cmu.edu/" >Carnegie Mellon University</a> advised by <a href="https://kriskitani.github.io/" > Prof. Kris Kitani</a>. My research at CMU is focussed on developing computer vision algorithms for Mixed Reality, specifically developing a visual-odometry algorithm for improving state estimation accuracy in Meta's <a href="https://about.meta.com/realitylabs/projectaria/" >Aria</a> glasses.
                </p>
                <p>
                  This summer, I interned at <a href="https://www.apple.com/" >Apple</a>, as a part of the Vision Products Group. I primarily developed a Video Anonymization Framework using generative model based data replacement techniques such as object removal using GAN based inpainting and face anonymization using conditional GANs.
                </p>
                <p>
                  I am a teaching assistant for <a href="https://www.cs.cmu.edu/~junyanz/" >Prof. Jun-Yan Zhu</a> for the course <a href="https://visual-learning.cs.cmu.edu/" >16-824: Visual Learning and Recognition</a>. 
                  Prior to joining CMU I worked as a Senior Machine Learning Engineer at <a href="https://research.samsung.com/sri-b" >Samsung Research</a>. I have a BTech in CS from <a href="http://www.eecs.berkeley.edu/" >IIT Dhanbad</a>.
                </p>
                
                <p style="text-align:center">
                  <a target="_blank" href="rmoharir@cs.cmu.edu" > Email</a> &nbsp;/&nbsp;
                  <a href="resumes/Moharir_Rutika_CMU_MSCV.pdf" > Resume </a> &nbsp;/&nbsp;                
                  <a href="https://www.linkedin.com/in/rutika-moharir-498a28143" > LinkedIn </a> &nbsp;/&nbsp;              
                  <!-- <a href="https://github.com/RMoharir" >GitHub</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=jK6hHlcAAAAJ&hl=en ">Google Scholar</a> &nbsp;/&nbsp; -->
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/self.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/self.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody>
        </table>

        <!-- LOGOS -->
        <table width="100%" align="center" border="0" cellpadding="10">
          </tbody>
            <tr>
              <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <a href="https://www.apple.com/"><img src = "images/apple-logo-transparent.png" width="50%"></a>
              </td>
    
              <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <a href="https://www.ri.cmu.edu/"><img src = images/CMU-logo.png width="50%"></a>
              </td>
    
              <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <a href="https://research.samsung.com/sri-b"><img src = "images/samsung-logo.jpeg" width="50%"></a>
              </td>
    
              <td align="center" width="16%" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
                <a href="https://www.iitism.ac.in/"><img src = "images/IIT-Dhanbad-logo.jpeg" width="50%"></a>
              </td>            
            </tr>
            
          </tbody>
        </table>
        
        <br><br>

        <!-- RESEARCH -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research</heading>
              </td>
            </tr>
          </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
              <td style="padding:20px;width:30%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='ddp_image'>
                    <img src='images/mrscatt_network.png' width="200"></div>
                  <img src='images/mrscatt_network.png' width="200">
                </div>
                <script type="text/javascript">
                  function ddp_start() {
                    document.getElementById('ddp_image').style.opacity = "1";
                  }
          
                  function ddp_stop() {
                    document.getElementById('ddp_image').style.opacity = "0";
                  }
                  ddp_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.pdf">
                  <papertitle>MRSCAtt: A Spatio-Channel Attention-Guided Network for Mars Rover Image Classification</papertitle>
                </a>
                <br>
                <strong>Anirudh Chakravarthy*</strong>,
                <a href="https://www.linkedin.com/in/rroshanroy/">Roshan Roy*</a>,
                <a href="https://www.linkedin.com/in/praveen-ravirathinam/">Praveen Ravirathinam*</a>
                <br>
                <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, 2021
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.pdf">[pdf]</a>
                <a href="https://github.com/anirudh-chakravarthy/MRSCAtt">[code]</a>
                
                <p></p>
                <p>
                  We propose a network, MRSCAtt (Mars Rover Spatial and Channel Attention), which jointly uses spatial and channel attention to accurately classify images. We use images taken by NASA's Curiosity rover on Mars as a dataset to show the superiority of our approach by achieving state-of-the-art results with 81.53% test set accuracy on the MSL Surface Dataset, outperforming other methods. 
                </p>
                
              </td>
            </tr>
          </tbody>
        </table>

    <br><br>

    <!-- PROJECTS -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Projects</heading>
          </td>
        </tr>
      </tbody>
    </table>
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>

        <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ddp_image'>
                <img src='images/monodepth_relpose.png' width="200"></div>
              <img src='images/monodepth_relpose.png' width="200">
            </div>
            <script type="text/javascript">
              function ddp_start() {
                document.getElementById('ddp_image').style.opacity = "1";
              }

              function ddp_stop() {
                document.getElementById('ddp_image').style.opacity = "0";
              }
              ddp_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Self-Supervised Camera Pose Estimation with Geometric Consistency</papertitle>
              <br>
              <a href="files/Monodepth+RelPose.pdf">[pdf]</a>
              <a href="https://github.com/vanshajc/self-supervised-relpose">[code]</a>
            <p></p>
            <p>
              Existing camera pose estimation methods make use of ground-truth odometry as supervision, which may be expensive to obtain.
              In this work, we train a transformer-based pose estimation network in a self-supervised manner, leveraging advances in monocular depth estimation.
            </p>
          </td>
        </tr>
      </tbody>
    </table>

  <br><br>

    <!-- PUBLICATIONS -->

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>PUBLICATIONS</heading>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
        <td style="padding:20px;width:30%;vertical-align:middle">
          <div class="one">
            <div class="two" id='ddp_image'>
              <img src='images/mrscatt_network.png' width="200"></div>
            <img src='images/mrscatt_network.png' width="200">
          </div>
          <script type="text/javascript">
            function ddp_start() {
              document.getElementById('ddp_image').style.opacity = "1";
            }

            function ddp_stop() {
              document.getElementById('ddp_image').style.opacity = "0";
            }
            ddp_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.pdf">
            <papertitle>MRSCAtt: A Spatio-Channel Attention-Guided Network for Mars Rover Image Classification</papertitle>
          </a>
          <br>
          <strong>Anirudh Chakravarthy*</strong>,
          <a href="https://www.linkedin.com/in/rroshanroy/">Roshan Roy*</a>,
          <a href="https://www.linkedin.com/in/praveen-ravirathinam/">Praveen Ravirathinam*</a>
          <br>
          <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, 2021
          <br>
          <a href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.pdf">[pdf]</a>
          <a href="https://github.com/anirudh-chakravarthy/MRSCAtt">[code]</a>
          
          <p></p>
          <p>
            We propose a network, MRSCAtt (Mars Rover Spatial and Channel Attention), which jointly uses spatial and channel attention to accurately classify images. We use images taken by NASA's Curiosity rover on Mars as a dataset to show the superiority of our approach by achieving state-of-the-art results with 81.53% test set accuracy on the MSL Surface Dataset, outperforming other methods. 
        </p>
          
        </td>
        </tr>
      </tbody>
    </table>
				
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody>
        <tr>
          <td>
            <heading>Highlights</heading>
          </td>
        </tr>
					
        <tr>
          <td>
              <strong>[May 2023]</strong> I joined the Vision Products Group at <a href="https://www.apple.com/">Apple</a> as a summer intern.<br>
              <strong>[Dec 2022]</strong> I started working as a Research Collaborator under the guidance of <a href="https://kriskitani.github.io/">Prof. Kris Kitani</a>.<br>
              <strong>[Aug 2022]</strong> I began my Masters in Computer Vision (MSCV) at the <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University </a>(CMU).<br>
              <strong>[June 2019]</strong> I joined <a href="https://research.samsung.com/sri-b">Samsung Research Institute Bangalore-India</a> as a Machine Leanrning Engineer.<br>
              <strong>[May 2019]</strong> I graduated from <a href="https://www.iitism.ac.in/">IIT Dhanbad, India</a> with a B.Tech in Computer Science.<br>
          </td>
        </tr>
      </tbody>
    </table>

        
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Source code from <a href="https://github.com/jonbarron/jonbarron_website"> here.</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody>
    </table>

  <small>
    <center>
    This page has been accessed at least
    <a href="http://stuff.mit.edu/doc/counter-howto.html"><img
            src="http://stuff.mit.edu/cgi/counter/rmoharir" alt="several"></a>
    times since 16th Sept. 2023.
    </center>
  </small>

</body>
</html>